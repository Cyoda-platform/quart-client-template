{
    "entity_models": [
        {
            "entity_model_name": "report",
            "workflow_function": {
                "code_with_necessary_imports_and_constants": "import asyncio\nimport logging\nfrom datetime import datetime, timezone\nfrom typing import Dict, Any\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)",
                "content": "async def process_report(entity: Dict[str, Any]) -> Dict[str, Any]:\n    report_id = entity.get(\"reportId\")\n    requested_at = entity.get(\"requestedAt\")\n    triggered_by = entity.get(\"triggeredBy\", \"unknown\")\n\n    logger.info(f\"Workflow process_report started for reportId: {report_id}\")\n\n    try:\n        books = await fetch_books()\n        analysis = analyze_books_data(books)\n        entity.update({\n            \"status\": \"completed\",\n            \"generatedOn\": datetime.now(timezone.utc).isoformat(),\n            **analysis,\n        })\n        await send_email_report(entity)\n        logger.info(f\"Workflow process_report completed successfully for reportId: {report_id}\")\n    except Exception as e:\n        logger.exception(f\"Error in workflow process_report for reportId {report_id}: {e}\")\n        entity.update({\n            \"status\": \"failed\",\n            \"error\": str(e),\n        })\n\n    entity['workflowAppliedAt'] = datetime.now(timezone.utc).isoformat()\n\n    return entity",
                "name": "process_report"
            }
        }
    ],
    "file_without_workflow": {
        "code": "import asyncio\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import datetime, timezone\nfrom typing import Dict, Any, Optional\nfrom quart import Quart, jsonify\nfrom quart_schema import QuartSchema, validate_request\nimport httpx\nimport uuid\n\nfrom app_init.app_init import BeanFactory\nfrom common.config.config import ENTITY_VERSION\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\nfactory = BeanFactory(config={'CHAT_REPOSITORY': 'cyoda'})\nentity_service = factory.get_services()['entity_service']\ncyoda_auth_service = factory.get_services()[\"cyoda_auth_service\"]\n\napp = Quart(__name__)\nQuartSchema(app)\n\nentity_name = \"report\"  # underscore lowercase\n\n@dataclass\nclass AnalyzeBooksRequest:\n    triggeredBy: str\n    date: Optional[str] = None\n\ndef parse_iso_date(date_str: str) -> Optional[datetime]:\n    try:\n        return datetime.fromisoformat(date_str.rstrip(\"Z\")).replace(tzinfo=timezone.utc)\n    except Exception:\n        logger.exception(f\"Failed to parse date: {date_str}\")\n        return None\n\nasync def fetch_books() -> Any:\n    async with httpx.AsyncClient(timeout=10.0) as client:\n        resp = await client.get(\"https://fakerestapi.azurewebsites.net/api/v1/Books\")\n        resp.raise_for_status()\n        return resp.json()\n\ndef analyze_books_data(books: list) -> Dict[str, Any]:\n    total_page_count = 0\n    publication_dates = []\n    for book in books:\n        page_count = book.get(\"pageCount\", 0) or 0\n        total_page_count += page_count\n        publish_date_str = book.get(\"publishDate\")\n        publish_date = parse_iso_date(publish_date_str)\n        if publish_date:\n            publication_dates.append(publish_date)\n\n    earliest = min(publication_dates).date().isoformat() if publication_dates else None\n    latest = max(publication_dates).date().isoformat() if publication_dates else None\n\n    sorted_books = sorted(books, key=lambda b: b.get(\"pageCount\", 0) or 0, reverse=True)\n    popular_titles = [\n        {\n            \"id\": b.get(\"id\"),\n            \"title\": b.get(\"title\"),\n            \"description\": b.get(\"description\"),\n            \"excerpt\": b.get(\"excerpt\"),\n            \"pageCount\": b.get(\"pageCount\"),\n            \"publishDate\": b.get(\"publishDate\"),\n        }\n        for b in sorted_books[:3]\n    ]\n\n    summary = (\n        f\"Analyzed {len(books)} books with a total of {total_page_count} pages. \"\n        f\"Publication dates range from {earliest} to {latest}. \"\n        f\"Top popular titles are based on highest page counts.\"\n    )\n\n    return {\n        \"totalBooks\": len(books),\n        \"totalPageCount\": total_page_count,\n        \"publicationDateRange\": {\"earliest\": earliest, \"latest\": latest},\n        \"popularTitles\": popular_titles,\n        \"summary\": summary,\n    }\n\nasync def send_email_report(report: Dict[str, Any]) -> None:\n    try:\n        # Placeholder for real email sending logic\n        logger.info(f\"Sending email report to analytics@example.com:\\n{report['summary']}\")\n        await asyncio.sleep(0.1)\n    except Exception:\n        logger.exception(\"Failed to send email report\")\n\n@app.route(\"/analyze-books\", methods=[\"POST\"])\n@validate_request(AnalyzeBooksRequest)\nasync def analyze_books(data: AnalyzeBooksRequest):\n    triggered_by = data.triggeredBy\n    requested_at = data.date or datetime.now(timezone.utc).isoformat()\n    job_id = str(uuid.uuid4())\n\n    initial_entity = {\n        \"reportId\": job_id,\n        \"status\": \"processing\",\n        \"requestedAt\": requested_at,\n        \"triggeredBy\": triggered_by,\n    }\n\n    try:\n        await entity_service.add_item(\n            token=cyoda_auth_service,\n            entity_model=entity_name,\n            entity_version=ENTITY_VERSION,\n            entity=initial_entity\n        )\n    except Exception as e:\n        logger.exception(f\"Failed to add initial report status for job {job_id}: {e}\")\n        return jsonify({\"status\": \"error\", \"message\": \"Failed to initiate analysis job.\"}), 500\n\n    return jsonify({\n        \"status\": \"success\",\n        \"message\": \"Book data analysis started.\",\n        \"reportId\": job_id,\n    })\n\n@app.route(\"/reports/<report_id>\", methods=[\"GET\"])\nasync def get_report(report_id):\n    try:\n        report = await entity_service.get_item(\n            token=cyoda_auth_service,\n            entity_model=entity_name,\n            entity_version=ENTITY_VERSION,\n            technical_id=report_id\n        )\n    except Exception as e:\n        logger.exception(f\"Failed to get report {report_id}: {e}\")\n        return jsonify({\"error\": \"Report not found\"}), 404\n\n    if not report:\n        return jsonify({\"error\": \"Report not found\"}), 404\n    if report.get(\"status\") == \"processing\":\n        return jsonify({\"status\": \"processing\"}), 202\n    if report.get(\"status\") == \"failed\":\n        return jsonify({\"status\": \"failed\", \"error\": report.get(\"error\")}), 500\n    return jsonify(report)\n\nif __name__ == '__main__':\n    app.run(use_reloader=False, debug=True, host='0.0.0.0', port=8000, threaded=True)\n"
    }
}